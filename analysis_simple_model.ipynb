{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = pd.read_csv(\"data/spam.csv\", encoding='latin-1')\n",
    "email_ds = pd.read_csv(\"data/spamassassin.csv\")\n",
    "\n",
    "# Shuffle the datasets\n",
    "text_ds = text_ds.sample(frac=1, random_state=42)[['label', 'text']]\n",
    "email_ds = email_ds.sample(frac=1, random_state=42)[['label', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some dataset preprocessing\n",
    "X_text = text_ds['text']\n",
    "y_text = text_ds['label']\n",
    "\n",
    "X_email = email_ds['text']\n",
    "y_email = email_ds['label']\n",
    "\n",
    "# Split the data\n",
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(\n",
    "    X_text, y_text, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_email_train, X_email_test, y_email_train, y_email_test = train_test_split(\n",
    "    X_email, y_email, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create TF-IDF features\n",
    "tfidf_text = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_text_train_tfidf = tfidf_text.fit_transform(X_text_train)\n",
    "X_text_test_tfidf = tfidf_text.transform(X_text_test)\n",
    "\n",
    "tfidf_email = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_email_train_tfidf = tfidf_email.fit_transform(X_email_train)\n",
    "X_email_test_tfidf = tfidf_email.transform(X_email_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_model(X_train, X_test, y_train, y_test, model_name, model):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy and spam recall\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    spam_recall = report['0']['recall']  # recall for class 0 (spam)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Overal Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"% of Spam Caught: {spam_recall:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes (Text Messages) Results:\n",
      "Overal Accuracy: 0.9836\n",
      "% of Spam Caught: 0.8824\n",
      "\n",
      "Logistic Regression (Text Messages) Results:\n",
      "Overal Accuracy: 0.9778\n",
      "% of Spam Caught: 0.9265\n",
      "\n",
      "Random Forest (Text Messages) Results:\n",
      "Overal Accuracy: 0.9787\n",
      "% of Spam Caught: 0.8897\n",
      "\n",
      "HistGradientBoosting (Text Messages) Results:\n",
      "Overal Accuracy: 0.9710\n",
      "% of Spam Caught: 0.9338\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models for text messages\n",
    "nb_text = train_evaluate_model(\n",
    "    X_text_train_tfidf, X_text_test_tfidf, \n",
    "    y_text_train, y_text_test,\n",
    "    \"Naive Bayes (Text Messages)\",\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "lr_text = train_evaluate_model(\n",
    "    X_text_train_tfidf, X_text_test_tfidf, \n",
    "    y_text_train, y_text_test,\n",
    "    \"Logistic Regression (Text Messages)\",\n",
    "    LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    ")\n",
    "\n",
    "rf_text = train_evaluate_model(\n",
    "    X_text_train_tfidf, X_text_test_tfidf, \n",
    "    y_text_train, y_text_test,\n",
    "    \"Random Forest (Text Messages)\",\n",
    "    RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "hgbt_text = train_evaluate_model(\n",
    "    X_text_train_tfidf.toarray(), X_text_test_tfidf.toarray(), \n",
    "    y_text_train, y_text_test,\n",
    "    \"HistGradientBoosting (Text Messages)\",\n",
    "    HistGradientBoostingClassifier(max_iter=100, class_weight='balanced')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Spam Indicators:\n",
      "txt: -4.6388\n",
      "mobile: -4.0876\n",
      "free: -3.5920\n",
      "claim: -3.5912\n",
      "uk: -3.5188\n",
      "150p: -3.3224\n",
      "service: -3.3055\n",
      "text: -3.2897\n",
      "www: -3.2653\n",
      "new: -3.0460\n",
      "\n",
      "Top 10 Ham Indicators:\n",
      "ll: 1.9452\n",
      "ok: 1.8341\n",
      "lt: 1.7559\n",
      "gt: 1.7467\n",
      "da: 1.6229\n",
      "home: 1.5653\n",
      "got: 1.4247\n",
      "way: 1.3929\n",
      "lor: 1.3849\n",
      "come: 1.3510\n",
      "\n",
      "Feature Frequency Analysis:\n",
      "\n",
      "Top 10 High-Impact, Low-Frequency Features:\n",
      "charity: Impact=-1.2642, Freq=2\n",
      "wap: Impact=-1.7276, Freq=5\n",
      "0800: Impact=-2.3104, Freq=7\n",
      "ac: Impact=-1.6422, Freq=6\n",
      "sunshine: Impact=-1.5940, Freq=6\n",
      "87077: Impact=-1.2605, Freq=5\n",
      "comuk: Impact=-0.7402, Freq=3\n",
      "00: Impact=-1.6077, Freq=7\n",
      "user: Impact=-1.5997, Freq=7\n",
      "20p: Impact=-1.5782, Freq=7\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_text.get_feature_names_out()\n",
    "\n",
    "# Get coefficients and their absolute values\n",
    "coefficients = lr_text.coef_[0]\n",
    "abs_coefficients = np.abs(coefficients)\n",
    "\n",
    "# Create a DataFrame of features and their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': abs_coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute coefficient value to get most important features\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "# Print top spam indicators (negative coefficients, as spam=0)\n",
    "print(\"\\nTop 10 Spam Indicators:\")\n",
    "spam_features = feature_importance[feature_importance['coefficient'] < 0].head(10)\n",
    "for idx, row in spam_features.iterrows():\n",
    "    print(f\"{row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "# Print top ham indicators (positive coefficients)\n",
    "print(\"\\nTop 10 Ham Indicators:\")\n",
    "ham_features = feature_importance[feature_importance['coefficient'] > 0].head(10)\n",
    "for idx, row in ham_features.iterrows():\n",
    "    print(f\"{row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "# Analyze feature frequency\n",
    "print(\"\\nFeature Frequency Analysis:\")\n",
    "X_train_array = X_text_train_tfidf.toarray()\n",
    "feature_freq = np.sum(X_train_array > 0, axis=0)\n",
    "freq_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'frequency': feature_freq,\n",
    "    'importance': abs_coefficients,\n",
    "    'true_importance': coefficients\n",
    "})\n",
    "freq_importance['freq_importance_ratio'] = freq_importance['importance'] / freq_importance['frequency']\n",
    "\n",
    "print(\"\\nTop 10 High-Impact, Low-Frequency Features:\")\n",
    "high_impact = freq_importance.sort_values('freq_importance_ratio', ascending=False).head(10)\n",
    "for idx, row in high_impact.iterrows():\n",
    "    print(f\"{row['feature']}: Impact={row['true_importance']:.4f}, Freq={row['frequency']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes (Emails) Results:\n",
      "Overal Accuracy: 0.9098\n",
      "% of Spam Caught: 0.8736\n",
      "\n",
      "Logistic Regression (Emails) Results:\n",
      "Overal Accuracy: 0.9738\n",
      "% of Spam Caught: 0.9753\n",
      "\n",
      "Random Forest (Emails) Results:\n",
      "Overal Accuracy: 0.9746\n",
      "% of Spam Caught: 0.9505\n",
      "\n",
      "HistGradientBoosting (Emails) Results:\n",
      "Overal Accuracy: 0.9820\n",
      "% of Spam Caught: 0.9780\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models for text messages\n",
    "nb_email = train_evaluate_model(\n",
    "    X_email_train_tfidf, X_email_test_tfidf, \n",
    "    y_email_train, y_email_test,\n",
    "    \"Naive Bayes (Emails)\",\n",
    "    MultinomialNB()\n",
    ")\n",
    "\n",
    "lr_email = train_evaluate_model(\n",
    "    X_email_train_tfidf, X_email_test_tfidf, \n",
    "    y_email_train, y_email_test,\n",
    "    \"Logistic Regression (Emails)\",\n",
    "    LogisticRegression(max_iter=10000, class_weight='balanced')\n",
    ")\n",
    "\n",
    "rf_email = train_evaluate_model(\n",
    "    X_email_train_tfidf, X_email_test_tfidf, \n",
    "    y_email_train, y_email_test,\n",
    "    \"Random Forest (Emails)\",\n",
    "    RandomForestClassifier(\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "hgbt_email = train_evaluate_model(\n",
    "    X_email_train_tfidf.toarray(), X_email_test_tfidf.toarray(), \n",
    "    y_email_train, y_email_test,\n",
    "    \"HistGradientBoosting (Emails)\",\n",
    "    HistGradientBoostingClassifier(max_iter=100, class_weight='balanced')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Spam Indicators:\n",
      "remove: -3.7749\n",
      "sightings: -3.7274\n",
      "free: -3.2335\n",
      "money: -3.1632\n",
      "center: -2.8821\n",
      "font: -2.8300\n",
      "br: -2.5963\n",
      "align: -2.5247\n",
      "nwe: -2.4083\n",
      "removed: -2.1524\n",
      "\n",
      "Top 10 Ham Indicators:\n",
      "cnet: 4.2253\n",
      "wrote: 3.6706\n",
      "lockergnome: 3.6045\n",
      "2002: 3.5972\n",
      "ndate: 3.0097\n",
      "url: 2.9741\n",
      "clickthru: 2.6644\n",
      "zdnet: 2.3449\n",
      "said: 2.3000\n",
      "spam: 2.2734\n",
      "\n",
      "Feature Frequency Analysis:\n",
      "\n",
      "Top 10 High-Impact, Low-Frequency Features:\n",
      "enenkio: Impact=-1.1781, Freq=2\n",
      "nmv: Impact=-0.6699, Freq=7\n",
      "lockergnome: Impact=3.6045, Freq=43\n",
      "mediaunspun: Impact=0.8271, Freq=10\n",
      "comics: Impact=1.1034, Freq=14\n",
      "unspun: Impact=0.6656, Freq=10\n",
      "dilbert: Impact=0.5899, Freq=9\n",
      "imakenews: Impact=0.6301, Freq=10\n",
      "tribute: Impact=0.2830, Freq=5\n",
      "fool: Impact=1.1109, Freq=21\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_email.get_feature_names_out()\n",
    "\n",
    "# Get coefficients and their absolute values\n",
    "coefficients = lr_email.coef_[0]\n",
    "abs_coefficients = np.abs(coefficients)\n",
    "\n",
    "# Create a DataFrame of features and their importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients,\n",
    "    'abs_coefficient': abs_coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute coefficient value to get most important features\n",
    "feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "# Print top spam indicators (negative coefficients, as spam=0)\n",
    "print(\"\\nTop 10 Spam Indicators:\")\n",
    "spam_features = feature_importance[feature_importance['coefficient'] < 0].head(10)\n",
    "for idx, row in spam_features.iterrows():\n",
    "    print(f\"{row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "# Print top ham indicators (positive coefficients)\n",
    "print(\"\\nTop 10 Ham Indicators:\")\n",
    "ham_features = feature_importance[feature_importance['coefficient'] > 0].head(10)\n",
    "for idx, row in ham_features.iterrows():\n",
    "    print(f\"{row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "# Analyze feature frequency\n",
    "print(\"\\nFeature Frequency Analysis:\")\n",
    "X_train_array = X_email_train_tfidf.toarray()\n",
    "feature_freq = np.sum(X_train_array > 0, axis=0)\n",
    "freq_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'frequency': feature_freq,\n",
    "    'importance': abs_coefficients,\n",
    "    'true_importance': coefficients\n",
    "})\n",
    "freq_importance['freq_importance_ratio'] = freq_importance['importance'] / freq_importance['frequency']\n",
    "\n",
    "print(\"\\nTop 10 High-Impact, Low-Frequency Features:\")\n",
    "high_impact = freq_importance.sort_values('freq_importance_ratio', ascending=False).head(10)\n",
    "for idx, row in high_impact.iterrows():\n",
    "    print(f\"{row['feature']}: Impact={row['true_importance']:.4f}, Freq={row['frequency']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_features(lr_model, tfidf, n=10):\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "    # Get coefficients and their absolute values\n",
    "    coefficients = lr_model.coef_[0]\n",
    "    abs_coefficients = np.abs(coefficients)\n",
    "\n",
    "    # Create a DataFrame of features and their importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'coefficient': coefficients,\n",
    "        'abs_coefficient': abs_coefficients\n",
    "    })\n",
    "\n",
    "    # Sort by absolute coefficient value to get most important features\n",
    "    feature_importance = feature_importance.sort_values('abs_coefficient', ascending=False)\n",
    "\n",
    "    # Print top spam indicators (negative coefficients, as spam=0)\n",
    "    print(\"\\nTop 10 Spam Indicators:\")\n",
    "    spam_features = feature_importance[feature_importance['coefficient'] < 0].head(n)\n",
    "    for idx, row in spam_features.iterrows():\n",
    "        print(f\"{row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "    # Print top ham indicators (positive coefficients)\n",
    "    print(\"\\nTop 10 Ham Indicators:\")\n",
    "    ham_features = feature_importance[feature_importance['coefficient'] > 0].head(n)\n",
    "    for idx, row in ham_features.iterrows():\n",
    "        print(f\"{row['feature']}: {row['coefficient']:.4f}\")\n",
    "\n",
    "    # Analyze feature frequency\n",
    "    print(\"\\nFeature Frequency Analysis:\")\n",
    "    X_train_array = X_email_train_tfidf.toarray()\n",
    "    feature_freq = np.sum(X_train_array > 0, axis=0)\n",
    "    freq_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'frequency': feature_freq,\n",
    "        'importance': abs_coefficients,\n",
    "        'true_importance': coefficients\n",
    "    })\n",
    "    freq_importance['freq_importance_ratio'] = freq_importance['importance'] / freq_importance['frequency']\n",
    "\n",
    "    print(\"\\nTop 10 High-Impact, Low-Frequency Features:\")\n",
    "    high_impact = freq_importance.sort_values('freq_importance_ratio', ascending=False).head(n)\n",
    "    for idx, row in high_impact.iterrows():\n",
    "        print(f\"{row['feature']}: Impact={row['true_importance']:.4f}, Freq={row['frequency']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Spam Indicators:\n",
      "remove: -3.7749\n",
      "sightings: -3.7274\n",
      "free: -3.2335\n",
      "money: -3.1632\n",
      "center: -2.8821\n",
      "font: -2.8300\n",
      "br: -2.5963\n",
      "align: -2.5247\n",
      "nwe: -2.4083\n",
      "removed: -2.1524\n",
      "\n",
      "Top 10 Ham Indicators:\n",
      "cnet: 4.2253\n",
      "wrote: 3.6706\n",
      "lockergnome: 3.6045\n",
      "2002: 3.5972\n",
      "ndate: 3.0097\n",
      "url: 2.9741\n",
      "clickthru: 2.6644\n",
      "zdnet: 2.3449\n",
      "said: 2.3000\n",
      "spam: 2.2734\n",
      "\n",
      "Feature Frequency Analysis:\n",
      "\n",
      "Top 10 High-Impact, Low-Frequency Features:\n",
      "enenkio: Impact=-1.1781, Freq=2\n",
      "nmv: Impact=-0.6699, Freq=7\n",
      "lockergnome: Impact=3.6045, Freq=43\n",
      "mediaunspun: Impact=0.8271, Freq=10\n",
      "comics: Impact=1.1034, Freq=14\n",
      "unspun: Impact=0.6656, Freq=10\n",
      "dilbert: Impact=0.5899, Freq=9\n",
      "imakenews: Impact=0.6301, Freq=10\n",
      "tribute: Impact=0.2830, Freq=5\n",
      "fool: Impact=1.1109, Freq=21\n"
     ]
    }
   ],
   "source": [
    "show_top_features(lr_email, tfidf_email, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
