{
  "transcript": "So you were the very first Harvard student to major in computer science. I hope you've put that in a frame somewhere. So for 40 years, you've been building and studying AI systems from both academic and entrepreneurial perspectives. You're the former CEO for artificial intelligence founded by the late Paul Allen. And in early 2024, you founded True Media, which we'll discuss. So thank you for being here. Okay, we'll roll with that. You've mentioned that we're in a race for AI supremacy. How high are the stakes? What are the biggest myths about AI? We're the best of humanity. Do you trust AI systems? Absolutely. System. You can use it. On a scale of one to 10, how powerful is today's AI relative to where it could go? Five. Six. Do you believe that AI can genuinely understand context? No. Great, terrible, great. Can AI... Creativity. I think... Creative. Is it possible for AI to be unbiased? No. How important is transparency in AI algorithms? A lot of us can't. What are reasonable and sensible guardrails when it comes to AI? So it's... Forward. Do we have to build AI systems with an off switch? It is... Do you think big tech would like that? I think they would. We'll make sure that AI software... What are some of the most interesting use cases that you're hearing with AI right now? It's... But they're not just... Search engine. Optimistic or pessimistic about AI deepening inequality? Which is... Which is... AI is being used to optimize drilling and fracking. Why are you optimistic that AI can help tackle climate change? Climate... What are some interesting use cases that you've heard companies try out for better or for worse? What are some of the most interesting use cases that you've heard companies try out for better or for worse? To improve performance. How does regulatory capture by lobbyists affect AI governance? What do you expect might happen under the Trump administration? It's... I expect... But... If you were able to enact one policy that you think would help AI at this stage, but not stifle innovation, what would that be? So that... So that... Well, then we're gonna jump into deepfakes and misinformation right now. Can you please tell us about TrueMedia? I understand it was used in countries all around the world. We still have tools like TrueMedia to help news organizations and other entities identify deepfakes. We... Is it obvious for the average person to spot a deepfake? It is... Do you think corporations... importance of identifying deepfakes and misinformation? I think they're... I think they're... Can you give us an example of a deepfake that could cause economic consequences? Do you see AI as replacing jobs? Do you see AI as replacing new information? Watch out. Do you see AI as replacing jobs? That's... Optimistic about the use of AI in education. I think it's... Press that. What industries do you think may be impacted by AI the most in the coming years? I think... I think... What about your field, computer science? Should coding still be taught in college? So... Oh, wow. What does that look like? Do you think that could make it less reliable? I think... Why didn't we see more targeted attacks during the elections in the United States? That's... Did social media platforms play a role in minimizing targeted attacks, do you think? No. So you talk to YouTube and big tech executives all the time. Are they ready to counteract potential threats? I think... What role should corporations have in pushing for regulation of AI? I think that... But... I think... What are you seeing so far? Are any companies leading the charge in a responsible way from your lens? I have... Could you talk about some failures you've seen? I think... This challenge. As companies look to address the use of AI in their own enterprises, who should be leading the charge? Is it the CIO, the CEO, general counsel? Absolutely. Do you think the average CEO understands AI enough to do that? How should they do that? Me. Okay. Are companies prepared to educate their employees on AI? This is... Would you say the... more confused than you would expect right now or less confused? I would... Reasons. And some... It's hard. It's... than that. So when it comes to warfare, what potential consequences could arise from unchecked proliferation of AI-powered weapons? I would say... Mistakes. What ethical considerations arise out of the development of autonomous weapon systems? It's incredibly... Systems. They're... An autonomous... Decision. Are you comfortable enough with AI to use AI-powered voice login for your retirement accounts? I call... Okay. Where does liability lie when AI fails, such as in the case of a self-driving car accident, an inaccurate credit assessment, or perhaps... Criminal sentencing recommendation? Excuse. Legal cases, are they in play right now? I'm watching... And so on. So when it comes to the media, where do you expect the New York Times case will go? I think... What are the implications for media right now? I think... For bait. Looking beyond deepfakes misinformation, what emerging risks do you see on the horizon? And how can businesses start preparing now? I think... You've expressed both concern and optimism about AI's future. What gives you hope? I think... Are you comfortable driving in Waymo cars right now? I think... Accidents. Will we face extinction with AI? No. Powerful... So what does it mean to be human in the era of advanced AI? I think... I hope... to live... Engaged...",
  "segments": {
    "0.00-3.24": "So you were the very first Harvard student",
    "3.24-5.24": "to major in computer science.",
    "23.20-25.78": "I hope you've put that in a frame somewhere.",
    "26.74-28.92": "So for 40 years, you've been building and studying",
    "28.92-30.72": "AI systems from both academic",
    "30.72-32.68": "and entrepreneurial perspectives.",
    "32.68-36.92": "You're the former CEO for artificial intelligence",
    "36.92-38.60": "founded by the late Paul Allen.",
    "38.60-41.48": "And in early 2024, you founded True Media,",
    "41.48-42.36": "which we'll discuss.",
    "42.36-43.80": "So thank you for being here.",
    "48.08-49.52": "Okay, we'll roll with that.",
    "49.52-52.70": "You've mentioned that we're in a race for AI supremacy.",
    "52.70-54.00": "How high are the stakes?",
    "58.92-61.80": "What are the biggest myths about AI?",
    "89.92-92.72": "We're the best of humanity.",
    "92.72-94.40": "Do you trust AI systems?",
    "94.40-95.24": "Absolutely.",
    "99.00-99.84": "System.",
    "99.84-100.88": "You can use it.",
    "108.76-111.88": "On a scale of one to 10, how powerful is today's AI",
    "111.88-113.56": "relative to where it could go?",
    "117.00-117.82": "Five.",
    "118.92-119.76": "Six.",
    "133.40-137.86": "Do you believe that AI can genuinely understand context?",
    "148.92-149.76": "No.",
    "161.68-163.48": "Great, terrible, great.",
    "164.32-165.26": "Can AI...",
    "166.04-166.88": "Creativity.",
    "166.88-167.70": "I think...",
    "177.04-177.88": "Creative.",
    "177.88-180.48": "Is it possible for AI to be unbiased?",
    "180.48-181.32": "No.",
    "198.04-201.24": "How important is transparency in AI algorithms?",
    "207.88-212.12": "A lot of us can't.",
    "212.12-215.24": "What are reasonable and sensible guardrails",
    "215.24-216.24": "when it comes to AI?",
    "229.40-230.24": "So it's...",
    "236.00-236.84": "Forward.",
    "236.84-239.80": "Do we have to build AI systems with an off switch?",
    "239.80-240.64": "It is...",
    "256.24-258.16": "Do you think big tech would like that?",
    "258.16-259.16": "I think they would.",
    "266.84-271.84": "We'll make sure that AI software...",
    "279.60-281.60": "What are some of the most interesting use cases",
    "281.60-283.92": "that you're hearing with AI right now?",
    "296.84-297.68": "It's...",
    "311.40-313.16": "But they're not just...",
    "313.16-314.08": "Search engine.",
    "316.32-319.96": "Optimistic or pessimistic about AI deepening inequality?",
    "324.00-324.84": "Which is...",
    "326.84-327.76": "Which is...",
    "349.80-352.64": "AI is being used to optimize drilling and fracking.",
    "352.64-355.64": "Why are you optimistic that AI can help tackle",
    "355.64-356.60": "climate change?",
    "356.60-357.44": "Climate...",
    "381.00-382.92": "What are some interesting use cases",
    "382.92-387.96": "that you've heard companies try out for better or for worse?",
    "413.92-415.92": "What are some of the most interesting use cases",
    "415.92-418.92": "that you've heard companies try out for better or for worse?",
    "426.12-427.68": "To improve performance.",
    "427.68-430.84": "How does regulatory capture by lobbyists",
    "430.84-432.16": "affect AI governance?",
    "443.92-445.08": "What do you expect might happen",
    "445.08-447.04": "under the Trump administration?",
    "447.04-447.88": "It's...",
    "449.64-450.48": "I expect...",
    "455.20-456.04": "But...",
    "467.84-471.32": "If you were able to enact one policy",
    "472.20-475.24": "that you think would help AI at this stage,",
    "475.24-477.56": "but not stifle innovation, what would that be?",
    "482.04-482.88": "So that...",
    "482.88-483.72": "So that...",
    "499.44-501.56": "Well, then we're gonna jump into deepfakes",
    "501.56-503.00": "and misinformation right now.",
    "503.00-504.96": "Can you please tell us about TrueMedia?",
    "512.88-517.88": "I understand it was used in countries all around the world.",
    "543.00-545.52": "We still have tools like TrueMedia",
    "545.52-547.88": "to help news organizations",
    "547.88-550.80": "and other entities identify deepfakes.",
    "550.80-551.64": "We...",
    "573.88-577.64": "Is it obvious for the average person to spot a deepfake?",
    "577.64-578.48": "It is...",
    "588.76-590.92": "Do you think corporations...",
    "590.92-594.12": "importance of identifying deepfakes and misinformation?",
    "594.12-594.96": "I think they're...",
    "602.88-604.20": "I think they're...",
    "617.20-619.24": "Can you give us an example of a deepfake",
    "619.24-622.12": "that could cause economic consequences?",
    "632.88-635.72": "Do you see AI as replacing jobs?",
    "635.72-638.00": "Do you see AI as replacing new information?",
    "638.00-638.84": "Watch out.",
    "642.20-645.12": "Do you see AI as replacing jobs?",
    "650.72-651.56": "That's...",
    "657.08-660.12": "Optimistic about the use of AI in education.",
    "662.88-664.04": "I think it's...",
    "671.96-672.80": "Press that.",
    "672.80-676.56": "What industries do you think may be impacted by AI the most",
    "676.56-677.72": "in the coming years?",
    "680.72-681.56": "I think...",
    "692.88-693.72": "I think...",
    "700.96-702.88": "What about your field, computer science?",
    "702.88-707.56": "Should coding still be taught in college?",
    "707.56-708.40": "So...",
    "723.88-724.72": "Oh, wow.",
    "724.72-726.16": "What does that look like?",
    "738.80-741.20": "Do you think that could make it less reliable?",
    "741.20-742.04": "I think...",
    "753.88-756.00": "Why didn't we see more targeted attacks",
    "756.00-758.20": "during the elections in the United States?",
    "758.20-759.04": "That's...",
    "783.88-786.20": "Did social media platforms play a role",
    "786.20-789.96": "in minimizing targeted attacks, do you think?",
    "789.96-791.44": "No.",
    "791.44-795.48": "So you talk to YouTube and big tech executives all the time.",
    "795.48-798.48": "Are they ready to counteract potential threats?",
    "813.88-814.72": "I think...",
    "824.36-826.64": "What role should corporations have",
    "826.64-830.08": "in pushing for regulation of AI?",
    "830.08-831.36": "I think that...",
    "836.72-837.56": "But...",
    "842.88-843.72": "I think...",
    "852.96-854.44": "What are you seeing so far?",
    "854.44-856.28": "Are any companies leading the charge",
    "856.28-858.64": "in a responsible way from your lens?",
    "858.64-859.48": "I have...",
    "865.32-867.68": "Could you talk about some failures you've seen?",
    "872.88-873.72": "I think...",
    "894.96-895.88": "This challenge.",
    "895.88-900.88": "As companies look to address the use of AI",
    "901.68-905.04": "in their own enterprises, who should be leading the charge?",
    "905.04-910.04": "Is it the CIO, the CEO, general counsel?",
    "910.36-911.20": "Absolutely.",
    "911.20-916.20": "Do you think the average CEO understands AI enough",
    "932.00-932.84": "to do that?",
    "936.96-938.16": "How should they do that?",
    "939.00-939.84": "Me.",
    "939.84-941.20": "Okay.",
    "970.16-973.72": "Are companies prepared to educate their employees on AI?",
    "973.72-974.56": "This is...",
    "986.32-987.96": "Would you say the...",
    "987.96-990.80": "more confused than you would expect right now",
    "990.80-992.80": "or less confused?",
    "992.80-993.64": "I would...",
    "1000.84-1001.68": "Reasons.",
    "1001.68-1002.88": "And some...",
    "1002.88-1003.72": "It's hard.",
    "1003.72-1004.56": "It's...",
    "1013.92-1014.76": "than that.",
    "1014.76-1016.92": "So when it comes to warfare,",
    "1016.92-1018.88": "what potential consequences could arise",
    "1018.88-1023.12": "from unchecked proliferation of AI-powered weapons?",
    "1029.84-1031.00": "I would say...",
    "1054.00-1054.96": "Mistakes.",
    "1054.96-1057.80": "What ethical considerations arise",
    "1057.84-1061.24": "out of the development of autonomous weapon systems?",
    "1061.24-1062.36": "It's incredibly...",
    "1065.00-1065.84": "Systems.",
    "1065.84-1066.68": "They're...",
    "1069.20-1070.32": "An autonomous...",
    "1086.04-1086.88": "Decision.",
    "1086.88-1088.92": "Are you comfortable enough with AI",
    "1088.92-1093.52": "to use AI-powered voice login for your retirement accounts?",
    "1093.52-1094.36": "I call...",
    "1110.08-1110.92": "Okay.",
    "1112.28-1115.60": "Where does liability lie when AI fails,",
    "1115.60-1118.20": "such as in the case of a self-driving car accident,",
    "1118.20-1120.60": "an inaccurate credit assessment,",
    "1120.60-1122.08": "or perhaps...",
    "1122.08-1124.28": "Criminal sentencing recommendation?",
    "1144.08-1144.92": "Excuse.",
    "1145.44-1147.52": "Legal cases, are they in play right now?",
    "1147.52-1148.36": "I'm watching...",
    "1155.96-1156.80": "And so on.",
    "1156.80-1158.04": "So when it comes to the media,",
    "1158.04-1160.56": "where do you expect the New York Times case will go?",
    "1160.56-1161.40": "I think...",
    "1169.00-1171.96": "What are the implications for media right now?",
    "1174.92-1175.76": "I think...",
    "1186.96-1187.80": "For bait.",
    "1187.80-1190.24": "Looking beyond deepfakes misinformation,",
    "1190.24-1193.44": "what emerging risks do you see on the horizon?",
    "1193.44-1195.96": "And how can businesses start preparing now?",
    "1204.92-1205.76": "I think...",
    "1222.00-1224.24": "You've expressed both concern and optimism",
    "1224.24-1225.48": "about AI's future.",
    "1225.48-1226.80": "What gives you hope?",
    "1234.92-1235.76": "I think...",
    "1254.44-1257.48": "Are you comfortable driving in Waymo cars right now?",
    "1264.92-1265.76": "I think...",
    "1269.00-1269.88": "Accidents.",
    "1269.88-1272.24": "Will we face extinction with AI?",
    "1272.24-1273.08": "No.",
    "1278.52-1279.36": "Powerful...",
    "1282.96-1285.12": "So what does it mean to be human",
    "1285.12-1287.52": "in the era of advanced AI?",
    "1288.64-1289.48": "I think...",
    "1295.16-1296.00": "I hope...",
    "1306.12-1307.16": "to live...",
    "1315.12-1315.96": "Engaged..."
  }
}