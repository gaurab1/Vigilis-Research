{
  "transcript": "In the early 80s, we didn't know, or at least Harvard wasn't sure, whether computer science is a fad or a bona fide academic discipline. And by the time I came around, they figured out this is a real thing. I was the first person to get their paper form signed for computer science major. Thank you for being here. It's a pleasure. The animating theme is AI for the common good. Because of national security and because of economic concerns, the stakes could not be higher. The biggest myth about AI is the one promulgated by Hollywood and the Terminator, that AI is a being, a monster, and that it's out. It's not a being. It's not out to get us. It's a tool. So be careful. You could get hurt. I think it's much more likely that AI will save us from climate change, from pandemics, from superbugs. And I want us to use it for the best for humanity. Absolutely not. In fact, I like to say, never trust an AI. But you have to be very careful to verify the output, make sure that what you're getting is real and trustworthy. AI today, I would give it a 7.4. A lot of people have an overblown notion of it. It's much better than it was even just three years ago. But as far as where it can go, the sky's the limit, but it will take time. Never mistake a clear view for a short distance. AI does understand context, and we see examples of that every day when we give nuanced queries to chat GPT. The thing is, it has what's called the jagged frontier. That means that sometimes it understands things really well, and you're like, this is amazing. And then the very next query, it's acting like some alien from another planet doesn't understand things at all. That's why it's jagged. I think that AI will augment human creativity, and it's already doing so. So writers, artists, many of us are using it to become more productive and more creative. The short answer is that it's incorporating the data that it accumulated, and that data contains biases. And it'll often amplify those. So AI is biased. The good news is if you just give it a different prompt, it can change its bias on a dime. Transparency is very important, but it's also very hard. You've got this neural network with billions of parameters. How the heck do you understand what's going on in there? I think that we need to identify the most dangerous outcomes, for example, using AI to construct bioweapons. And we need to ensure that queries along those lines are not answered. It's identify the most worrying outcomes and put in guardrails to prevent those from coming forward. It's absolutely essential. So I wrote in the New York Times in 2017 that AI systems should have an impregnable off-switch. And that's one of the things that will help to keep us safe as the technology becomes more powerful and has increased autonomy. I think it's good because it reduces some of the liability concerns. And it's a safety device. It doesn't slow things down. It doesn't create additional expense. It's just a system of the last resort. So the same way that we can take our computer and just unplug it from the wall, make sure that we have an off-switch for our AI. AI is the new electricity, Andrew Ng said, so literally in every domain of discourse from human sexuality to education to HR and finance to high-frequency trading, people are using AI all over the place. One of my favorite examples is people using it to practice their negotiation skills. They can put the AI as an adversary. They can put the AI to argue better on their behalf. Using it as a fan. They're using it for role play. I think that actually people are missing a key point here, which AI can be used for assistive intelligence. If we think about people who are disabled in wheelchairs with difficulty seeing and hearing and so on, AI can be a tremendous boon to them. So I view AI as having a tremendous potential to help some of the most marginalized communities in the world. Now, when it comes to income inequality, of course, we have some challenges. Climate change is a huge problem with many dimensions, but one really important one is better carbon sequestration, which requires tremendous innovation. Basically, the technologies that we have today will not solve the problem fast enough. We need to invent new technologies and new science, and AI is fantastic in helping our leading scientists do that. There are so many, for example, regulatory compliance. There's so much difficult and complex compliance information. And guess what? AI is really good at reading through documents and figuring out how to do compliance. We have legal outcomes where law firms are using AI to generate, but more efficiently, to read and manage contracts. So legal departments are using it. I would say in coding, we're starting to be more productive. It's really the case that in every single department of the corporation, from HR to the janitorial staff, there are opportunities to use AI. A lot of the regulations that we've seen have been shaped by large tech to their benefit and to the detriment of startups. For that reason, I'm quite skeptical about some of the regulatory efforts that we're seeing. It's very hard to predict, isn't it, that Elon Musk's companies will fare very well? In a less cynical sense, I do see some very well-intentioned and talented folks from Silicon Valley and from the tech industry moving into government and trying to have a positive impact. I would say that AI has to be labeled, that if you pick up your phone and you hear a voice on the other end, you don't know whether that's a person or a machine. So AI should identify itself. When you get an email or a text message on the internet, who knows who's at the other end? Again, AI should self-identify. Truemedia.org is a nonprofit that I founded with the backing of Garrett Camp, the co-founder of Uber, to fight political deepfakes in 2024, an election year all over the globe. We are very pleased that in Indonesia, in India, in Europe, in numerous countries, news organizations and fact-checkers used our tool to identify thousands of fake items as fake. It was used to take down Russian disinformation sites. And of course, it was used in our own election in a variety of ways. We are open-sourcing our models to make them broadly available, as well as our data and resources. So we will have that. I think we could have more because a lot of the resources are behind the paywall under lock and key. And we need things that are available to news organizations that don't necessarily have a deep pocket. It's very non-obvious. And there's been a bunch of research that shows that people's ability to detect whether something is fake or real is no better than their ability to predict and understand the importance of the information. But I think it's going to get worse before it gets better. And we have the cases of money being wired out of a corporation due to a fake Zoom call. And I think we're going to have more problems like this before people are fully on board with the need to determine whether a communication video, audio or otherwise is fake or real. I think we've seen one. There was a photo a few years ago propagated of the Pentagon being bombed that caused the glitch in the market. I think there are many other such things. Our economy and the markets are so quick to react to new information that we have to watch and determine whether that information is fake or real. What we see right now is AI augmenting people by automating tasks. Over time, it will replace some jobs, particularly ones that are very rote. I am very optimistic about it because particularly in the developing world, we don't have the resources to provide the quality of education that people need and AI can help address that. Every single one. I think that the more regulated and entrenched industries will be slower. Ones that have a physical nature like construction of houses and bridges will be slower. But I think finance, I think knowledge work of many kinds is going to be impacted very quickly and already is. So, coding is already becoming faster and more productive. It still needs to be taught because the fact of the matter is even our most advanced AIs cannot write complex original programs. So, coding is not going to disappear, but it's going to be on steroids. We are always impatient, right? When is going to be the next step? We are always impatient, right? When is going to be the next release of the software? When are they going to fix this bug? Why can't they build this website more quickly? Now, things are going to start to accelerate. It could make it less reliable, so we have to put the appropriate tests in place. The good news is that quality assurance of software is in itself a software process. So, quality assurance is going to get better as well. It's a mystery to me. In the past, we used to have deterrence, right? If state actors intervened too much in our process, we had ways of getting back at them. Now, it's so easy to do some of this disinformation, deepfake, cyber attack. I'm surprised we didn't see more of that. What we did see on the rise is ransomware attacks, and that's continuing to rise, and it's a major concern. What do you think is the best way to fight ransomware? I think they are very well positioned to fight the last war. So, if there is a single video or image that is having a disproportionately bad impact, they're well positioned to take it down or to downweight it. But a concerted attack of thousands of deepfakes being propagated by hundreds of thousands of fake accounts, I don't think we're ready for. Corporations benefit from a rational, meaning not too much, not too little, unified framework. So, when you have no regulation, you find a patchwork of local and state and city regulations, which are problematic. So, I think what we ought to aim for is not more regulation, but better and more unified regulation. I haven't seen a tremendous amount of corporate leadership on AI regulation. Well, for example, in the world of deepfakes, corporations banded together to produce the C2PA, basically content provenance, and unfortunately, that's highly impractical. What we really need is decisions on how information is propagated across social media, and we have not seen social media networks, be they meta or X or TikTok, step up to that. I think we need to lead the CEO because the potential here is for lower costs and higher revenue, much faster time to market. So, this isn't something you delegate to any of those roles. I think the CEO needs to be leading the charge because there's so much potential there. I think the average CEO should educate themselves, so they do. And how? Well, they could talk to. I do think that it's a conversation that needs to be had. I think it's a conversation that needs to be had. I think it's a conversation that needs to be had. I think it's a conversation that needs to be had. I do think that it's a conversation that we ought to be having both with AI experts, but also with just gaining hands-on literacy with the machines. So, if you're an executive and you're not spending quality time with Chad GPT, Claude, or what have you, trying to figure out how to optimize aspects of your business, what it can and can't do, you're missing an opportunity. This is very fresh technology, and we're building this airplane as we're flying it. So, no, I wouldn't say that they're ready, but the tools and the curricula are emerging. I would say that there's more inertia than I would have expected. It's proceeding slowly for a variety of reasons. Some of it is because it's not turnkey. So, when we say AI is the new electricity, that suggests that it's plug-and-play. You just stick something into the wall, and AI flows out. It is more complicated. AI-powered weapons are increasingly fast, requiring an increasingly fast response, right? A guided missile is coming in. You don't have time to react. Swarms of drones are coming in. They're coordinating. You have to launch a response. So, if the pace of warfare and the pace of AI is slow, you have to launch a response. So, if the pace of warfare and the pace of weapons gets faster and faster, that leads us to have increased automation, which is very worrying, because, as we know, AI is brittle. It can make terrible decisions. It's really important to distinguish between intelligence, increasingly sophisticated. It could be increasingly accurate. They make a decision to take a human life without a human in the loop. They decide on their own. I'm very much pro-intelligence systems, intelligent weapons even, but I'm very opposed to autonomous weapons, because I think a human still has to make that weighty moral decision. My broker and told them to disable it, because I don't trust it. I asked it, how do you know that my voice is my password? They said, well, we use AI. And I said, no, I study AI, and I don't trust it, so please disable it. And I would recommend that to all of you. There are different cases, and sometimes it's the manufacturer, sometimes it's the creator of the software system. It's a complicated issue. But the overriding principle, which is really important, is that it needs to end up with a person or a corporation. My AI did it is not an excuse. It's not an excuse. It's not an excuse. It's not an excuse. It's not an excuse. It's not an excuse. It's not an excuse. It's not an excuse. My AI did it is not an excuse. In cases, for example, the copyright issue, which is a very important one for society, right, between the OpenAI and the New York Times. I think that it's been well documented that OpenAI and other companies overstepped and violated copyright law. Media needs to decide for their content, what are they willing to put out there that AI can train on, and what they want to keep proprietary. And then they need to consider how to make sure that their wishes are Cybersecurity is a huge risk that comes to mind. So phishing attacks can become more sophisticated. Probing of holes in your network and in your software can become more sophisticated using AI. So I think that we need to ramp up our AI cybersecurity defense to prepare for more AI cybersecurity offense. What gives me hope is the fact that there are so many things that we as humans do so badly, like driving, which causes 40,000 deaths in our highways each year. Like hospital work, where the third leading cause of death is physician error. By augmenting drivers, physicians, nurses with AI systems, we can drive these statistics to the point where we can drive these statistics down and save people's lives. I am comfortable. What I'm sad about is how slowly the propagation is. I wish that we had them everywhere so that they could save lives and reduce the number of That is overblown, that is science fiction, because we're talking about tools, but not beings who are going to take over. I think it means the same thing it's always meant, but it is in a different technological context. But there's nothing new here, right? We used to work in agriculture. Now we're having a conversation. We used to not have the internet. Now we do. But we're still going to live and love and hate, unfortunately, and go through our lives in a fundamentally human way.",
  "segments": {
    "0.00-10.62": "In the early 80s, we didn't know, or at least Harvard wasn't sure, whether computer science",
    "10.62-14.20": "is a fad or a bona fide academic discipline.",
    "14.20-17.92": "And by the time I came around, they figured out this is a real thing.",
    "17.92-23.00": "I was the first person to get their paper form signed for computer science major.",
    "30.00-43.64": "Thank you for being here.",
    "43.64-44.64": "It's a pleasure.",
    "44.64-54.40": "The animating theme is AI for the common good.",
    "54.40-58.96": "Because of national security and because of economic concerns, the stakes could not",
    "58.96-59.96": "be higher.",
    "59.96-68.00": "The biggest myth about AI is the one promulgated by Hollywood and the Terminator, that AI is",
    "68.00-72.22": "a being, a monster, and that it's out.",
    "72.22-73.22": "It's not a being.",
    "73.22-74.62": "It's not out to get us.",
    "74.62-75.62": "It's a tool.",
    "75.62-77.28": "So be careful.",
    "77.28-78.28": "You could get hurt.",
    "78.28-85.80": "I think it's much more likely that AI will save us from climate change, from pandemics,",
    "85.80-87.80": "from superbugs.",
    "87.80-93.24": "And I want us to use it for the best for humanity.",
    "93.24-96.24": "Absolutely not.",
    "96.24-101.04": "In fact, I like to say, never trust an AI.",
    "101.04-106.36": "But you have to be very careful to verify the output, make sure that what you're getting",
    "106.44-109.44": "is real and trustworthy.",
    "109.44-117.96": "AI today, I would give it a 7.4.",
    "117.96-120.84": "A lot of people have an overblown notion of it.",
    "120.84-124.84": "It's much better than it was even just three years ago.",
    "124.84-129.92": "But as far as where it can go, the sky's the limit, but it will take time.",
    "129.92-133.04": "Never mistake a clear view for a short distance.",
    "137.36-143.56": "AI does understand context, and we see examples of that every day when we give nuanced queries",
    "143.56-145.16": "to chat GPT.",
    "145.16-148.64": "The thing is, it has what's called the jagged frontier.",
    "148.64-153.72": "That means that sometimes it understands things really well, and you're like, this is amazing.",
    "153.72-158.72": "And then the very next query, it's acting like some alien from another planet doesn't",
    "158.72-160.28": "understand things at all.",
    "160.28-161.28": "That's why it's jagged.",
    "161.28-171.28": "I think that AI will augment human creativity, and it's already doing so.",
    "171.28-181.56": "So writers, artists, many of us are using it to become more productive and more creative.",
    "181.56-187.88": "The short answer is that it's incorporating the data that it accumulated, and that data",
    "187.88-189.36": "contains biases.",
    "189.44-191.24": "And it'll often amplify those.",
    "191.24-192.84": "So AI is biased.",
    "192.84-197.84": "The good news is if you just give it a different prompt, it can change its bias on a dime.",
    "201.24-204.04": "Transparency is very important, but it's also very hard.",
    "204.04-207.32": "You've got this neural network with billions of parameters.",
    "207.32-210.84": "How the heck do you understand what's going on in there?",
    "211.32-221.32": "I think that we need to identify the most dangerous outcomes, for example, using AI",
    "221.32-223.36": "to construct bioweapons.",
    "223.36-230.44": "And we need to ensure that queries along those lines are not answered.",
    "230.44-235.92": "It's identify the most worrying outcomes and put in guardrails to prevent those from coming",
    "235.92-236.92": "forward.",
    "236.92-241.16": "It's absolutely essential.",
    "241.16-247.68": "So I wrote in the New York Times in 2017 that AI systems should have an impregnable off-switch.",
    "247.68-253.20": "And that's one of the things that will help to keep us safe as the technology becomes",
    "253.20-256.00": "more powerful and has increased autonomy.",
    "256.00-263.56": "I think it's good because it reduces some of the liability concerns.",
    "263.56-265.12": "And it's a safety device.",
    "265.12-267.04": "It doesn't slow things down.",
    "267.04-269.36": "It doesn't create additional expense.",
    "269.36-271.92": "It's just a system of the last resort.",
    "271.92-277.24": "So the same way that we can take our computer and just unplug it from the wall, make sure",
    "277.24-278.96": "that we have an off-switch for our AI.",
    "283.96-290.44": "AI is the new electricity, Andrew Ng said, so literally in every domain of discourse",
    "290.76-298.12": "from human sexuality to education to HR and finance to high-frequency trading, people",
    "298.12-300.72": "are using AI all over the place.",
    "300.72-306.48": "One of my favorite examples is people using it to practice their negotiation skills.",
    "306.48-308.64": "They can put the AI as an adversary.",
    "308.64-312.36": "They can put the AI to argue better on their behalf.",
    "312.36-314.24": "Using it as a fan.",
    "314.24-315.80": "They're using it for role play.",
    "315.80-327.52": "I think that actually people are missing a key point here, which AI can be used for",
    "327.52-329.32": "assistive intelligence.",
    "329.32-334.12": "If we think about people who are disabled in wheelchairs with difficulty seeing and",
    "334.12-337.76": "hearing and so on, AI can be a tremendous boon to them.",
    "337.76-344.68": "So I view AI as having a tremendous potential to help some of the most marginalized communities",
    "344.68-345.68": "in the world.",
    "345.68-348.96": "Now, when it comes to income inequality, of course, we have some challenges.",
    "356.96-363.32": "Climate change is a huge problem with many dimensions, but one really important one is",
    "363.32-367.64": "better carbon sequestration, which requires tremendous innovation.",
    "367.64-373.12": "Basically, the technologies that we have today will not solve the problem fast enough.",
    "373.12-379.40": "We need to invent new technologies and new science, and AI is fantastic in helping our",
    "379.40-380.88": "leading scientists do that.",
    "387.88-390.92": "There are so many, for example, regulatory compliance.",
    "390.92-394.92": "There's so much difficult and complex compliance information.",
    "394.92-395.92": "And guess what?",
    "395.92-400.20": "AI is really good at reading through documents and figuring out how to do compliance.",
    "400.28-408.88": "We have legal outcomes where law firms are using AI to generate, but more efficiently,",
    "408.88-410.84": "to read and manage contracts.",
    "410.84-412.28": "So legal departments are using it.",
    "412.28-416.56": "I would say in coding, we're starting to be more productive.",
    "416.56-422.40": "It's really the case that in every single department of the corporation, from HR to",
    "422.40-425.80": "the janitorial staff, there are opportunities to use AI.",
    "430.80-438.32": "A lot of the regulations that we've seen have been shaped by large tech to their benefit",
    "438.32-440.80": "and to the detriment of startups.",
    "440.80-444.96": "For that reason, I'm quite skeptical about some of the regulatory efforts that we're",
    "444.96-445.96": "seeing.",
    "448.96-457.16": "It's very hard to predict, isn't it, that Elon Musk's companies will fare very well?",
    "457.16-463.64": "In a less cynical sense, I do see some very well-intentioned and talented folks from Silicon",
    "463.64-468.96": "Valley and from the tech industry moving into government and trying to have a positive impact.",
    "477.96-486.12": "I would say that AI has to be labeled, that if you pick up your phone and you hear a voice",
    "486.12-489.92": "on the other end, you don't know whether that's a person or a machine.",
    "489.92-491.64": "So AI should identify itself.",
    "491.64-495.88": "When you get an email or a text message on the internet, who knows who's at the other",
    "495.88-496.88": "end?",
    "496.88-498.88": "Again, AI should self-identify.",
    "505.88-511.00": "Truemedia.org is a nonprofit that I founded with the backing of Garrett Camp, the co-founder",
    "511.00-517.76": "of Uber, to fight political deepfakes in 2024, an election year all over the globe.",
    "521.76-527.88": "We are very pleased that in Indonesia, in India, in Europe, in numerous countries, news",
    "527.88-535.64": "organizations and fact-checkers used our tool to identify thousands of fake items as fake.",
    "535.64-538.84": "It was used to take down Russian disinformation sites.",
    "539.68-542.68": "And of course, it was used in our own election in a variety of ways.",
    "551.68-556.68": "We are open-sourcing our models to make them broadly available, as well as our data and",
    "556.68-557.68": "resources.",
    "557.68-559.76": "So we will have that.",
    "559.76-565.84": "I think we could have more because a lot of the resources are behind the paywall under",
    "565.84-567.16": "lock and key.",
    "567.16-572.12": "And we need things that are available to news organizations that don't necessarily have",
    "572.12-573.12": "a deep pocket.",
    "578.12-579.36": "It's very non-obvious.",
    "579.36-583.52": "And there's been a bunch of research that shows that people's ability to detect whether",
    "583.52-590.72": "something is fake or real is no better than their ability to predict and understand the",
    "590.72-591.72": "importance of the information.",
    "595.72-598.80": "But I think it's going to get worse before it gets better.",
    "598.80-606.00": "And we have the cases of money being wired out of a corporation due to a fake Zoom call.",
    "606.00-610.24": "And I think we're going to have more problems like this before people are fully on board",
    "610.24-616.96": "with the need to determine whether a communication video, audio or otherwise is fake or real.",
    "621.72-623.72": "I think we've seen one.",
    "623.72-628.96": "There was a photo a few years ago propagated of the Pentagon being bombed that caused the",
    "628.96-630.40": "glitch in the market.",
    "630.40-632.56": "I think there are many other such things.",
    "632.56-639.40": "Our economy and the markets are so quick to react to new information that we have to watch",
    "639.40-641.72": "and determine whether that information is fake or real.",
    "644.72-649.72": "What we see right now is AI augmenting people by automating tasks.",
    "651.72-656.72": "Over time, it will replace some jobs, particularly ones that are very rote.",
    "659.72-666.20": "I am very optimistic about it because particularly in the developing world, we don't have the",
    "666.20-672.72": "resources to provide the quality of education that people need and AI can help address that.",
    "678.72-679.72": "Every single one.",
    "680.72-684.72": "I think that the more regulated and entrenched industries will be slower.",
    "684.72-691.72": "Ones that have a physical nature like construction of houses and bridges will be slower.",
    "691.72-698.72": "But I think finance, I think knowledge work of many kinds is going to be impacted very",
    "698.72-700.72": "quickly and already is.",
    "701.72-707.72": "So, coding is already becoming faster and more productive.",
    "707.72-712.72": "It still needs to be taught because the fact of the matter is even our most advanced AIs",
    "712.72-715.72": "cannot write complex original programs.",
    "715.72-720.72": "So, coding is not going to disappear, but it's going to be on steroids.",
    "723.72-725.72": "We are always impatient, right?",
    "725.72-727.72": "When is going to be the next step?",
    "727.72-729.72": "We are always impatient, right?",
    "729.72-731.72": "When is going to be the next release of the software?",
    "731.72-733.72": "When are they going to fix this bug?",
    "733.72-736.72": "Why can't they build this website more quickly?",
    "736.72-739.72": "Now, things are going to start to accelerate.",
    "742.72-746.72": "It could make it less reliable, so we have to put the appropriate tests in place.",
    "746.72-751.72": "The good news is that quality assurance of software is in itself a software process.",
    "751.72-754.72": "So, quality assurance is going to get better as well.",
    "758.72-760.72": "It's a mystery to me.",
    "760.72-762.72": "In the past, we used to have deterrence, right?",
    "762.72-767.72": "If state actors intervened too much in our process, we had ways of getting back at them.",
    "767.72-773.72": "Now, it's so easy to do some of this disinformation, deepfake, cyber attack.",
    "773.72-776.72": "I'm surprised we didn't see more of that.",
    "776.72-781.72": "What we did see on the rise is ransomware attacks, and that's continuing to rise,",
    "781.72-783.72": "and it's a major concern.",
    "787.72-798.72": "What do you think is the best way to fight ransomware?",
    "798.72-803.72": "I think they are very well positioned to fight the last war.",
    "803.72-810.72": "So, if there is a single video or image that is having a disproportionately bad impact,",
    "810.72-814.72": "they're well positioned to take it down or to downweight it.",
    "814.72-821.72": "But a concerted attack of thousands of deepfakes being propagated by hundreds of thousands of fake accounts,",
    "821.72-823.72": "I don't think we're ready for.",
    "830.72-837.72": "Corporations benefit from a rational, meaning not too much, not too little, unified framework.",
    "837.72-845.72": "So, when you have no regulation, you find a patchwork of local and state and city regulations, which are problematic.",
    "845.72-852.72": "So, I think what we ought to aim for is not more regulation, but better and more unified regulation.",
    "858.72-864.72": "I haven't seen a tremendous amount of corporate leadership on AI regulation.",
    "867.72-874.72": "Well, for example, in the world of deepfakes, corporations banded together to produce the C2PA,",
    "874.72-880.72": "basically content provenance, and unfortunately, that's highly impractical.",
    "880.72-887.72": "What we really need is decisions on how information is propagated across social media,",
    "887.72-894.72": "and we have not seen social media networks, be they meta or X or TikTok, step up to that.",
    "898.72-907.72": "I think we need to lead the CEO because the potential here is for lower costs and higher revenue, much faster time to market.",
    "907.72-911.72": "So, this isn't something you delegate to any of those roles.",
    "911.72-916.72": "I think the CEO needs to be leading the charge because there's so much potential there.",
    "917.72-921.72": "I think the average CEO should educate themselves, so they do.",
    "921.72-922.72": "And how?",
    "922.72-923.72": "Well, they could talk to.",
    "926.72-931.72": "I do think that it's a conversation that needs to be had.",
    "931.72-934.72": "I think it's a conversation that needs to be had.",
    "934.72-937.72": "I think it's a conversation that needs to be had.",
    "937.72-940.72": "I think it's a conversation that needs to be had.",
    "941.72-948.72": "I do think that it's a conversation that we ought to be having both with AI experts,",
    "948.72-953.72": "but also with just gaining hands-on literacy with the machines.",
    "953.72-962.72": "So, if you're an executive and you're not spending quality time with Chad GPT, Claude, or what have you,",
    "962.72-967.72": "trying to figure out how to optimize aspects of your business, what it can and can't do,",
    "967.72-969.72": "you're missing an opportunity.",
    "971.72-978.72": "This is very fresh technology, and we're building this airplane as we're flying it.",
    "978.72-984.72": "So, no, I wouldn't say that they're ready, but the tools and the curricula are emerging.",
    "991.72-996.72": "I would say that there's more inertia than I would have expected.",
    "997.72-1001.72": "It's proceeding slowly for a variety of reasons.",
    "1001.72-1004.72": "Some of it is because it's not turnkey.",
    "1004.72-1009.72": "So, when we say AI is the new electricity, that suggests that it's plug-and-play.",
    "1009.72-1012.72": "You just stick something into the wall, and AI flows out.",
    "1012.72-1013.72": "It is more complicated.",
    "1014.72-1021.72": "AI-powered weapons are increasingly fast, requiring an increasingly fast response, right?",
    "1021.72-1023.72": "A guided missile is coming in.",
    "1023.72-1026.72": "You don't have time to react.",
    "1026.72-1028.72": "Swarms of drones are coming in.",
    "1028.72-1029.72": "They're coordinating.",
    "1029.72-1031.72": "You have to launch a response.",
    "1031.72-1037.72": "So, if the pace of warfare and the pace of AI is slow,",
    "1038.72-1040.72": "you have to launch a response.",
    "1040.72-1045.72": "So, if the pace of warfare and the pace of weapons gets faster and faster,",
    "1045.72-1050.72": "that leads us to have increased automation, which is very worrying,",
    "1050.72-1052.72": "because, as we know, AI is brittle.",
    "1052.72-1054.72": "It can make terrible decisions.",
    "1061.72-1064.72": "It's really important to distinguish between intelligence,",
    "1065.72-1066.72": "increasingly sophisticated.",
    "1066.72-1068.72": "It could be increasingly accurate.",
    "1069.72-1073.72": "They make a decision to take a human life without a human in the loop.",
    "1073.72-1075.72": "They decide on their own.",
    "1075.72-1079.72": "I'm very much pro-intelligence systems, intelligent weapons even,",
    "1079.72-1081.72": "but I'm very opposed to autonomous weapons,",
    "1081.72-1085.72": "because I think a human still has to make that weighty moral decision.",
    "1086.72-1091.72": "My broker and told them to disable it, because I don't trust it.",
    "1091.72-1094.72": "I asked it, how do you know that my voice is my password?",
    "1094.72-1096.72": "They said, well, we use AI.",
    "1096.72-1100.72": "And I said, no, I study AI, and I don't trust it, so please disable it.",
    "1100.72-1102.72": "And I would recommend that to all of you.",
    "1115.72-1118.72": "There are different cases, and sometimes it's the manufacturer,",
    "1118.72-1122.72": "sometimes it's the creator of the software system.",
    "1122.72-1124.72": "It's a complicated issue.",
    "1124.72-1127.72": "But the overriding principle, which is really important,",
    "1127.72-1131.72": "is that it needs to end up with a person or a corporation.",
    "1131.72-1134.72": "My AI did it is not an excuse.",
    "1134.72-1135.72": "It's not an excuse.",
    "1135.72-1136.72": "It's not an excuse.",
    "1136.72-1137.72": "It's not an excuse.",
    "1137.72-1138.72": "It's not an excuse.",
    "1138.72-1139.72": "It's not an excuse.",
    "1139.72-1140.72": "It's not an excuse.",
    "1140.72-1141.72": "It's not an excuse.",
    "1141.72-1144.72": "My AI did it is not an excuse.",
    "1147.72-1150.72": "In cases, for example, the copyright issue,",
    "1150.72-1153.72": "which is a very important one for society, right,",
    "1153.72-1155.72": "between the OpenAI and the New York Times.",
    "1160.72-1165.72": "I think that it's been well documented that OpenAI and other companies",
    "1165.72-1168.72": "overstepped and violated copyright law.",
    "1171.72-1175.72": "Media needs to decide for their content,",
    "1175.72-1179.72": "what are they willing to put out there that AI can train on,",
    "1179.72-1181.72": "and what they want to keep proprietary.",
    "1181.72-1186.72": "And then they need to consider how to make sure that their wishes are",
    "1195.72-1198.72": "Cybersecurity is a huge risk that comes to mind.",
    "1198.72-1202.72": "So phishing attacks can become more sophisticated.",
    "1202.72-1207.72": "Probing of holes in your network and in your software",
    "1207.72-1210.72": "can become more sophisticated using AI.",
    "1210.72-1217.72": "So I think that we need to ramp up our AI cybersecurity defense",
    "1217.72-1221.72": "to prepare for more AI cybersecurity offense.",
    "1222.72-1226.72": "What gives me hope is the fact that there are so many things",
    "1226.72-1230.72": "that we as humans do so badly, like driving,",
    "1230.72-1234.72": "which causes 40,000 deaths in our highways each year.",
    "1234.72-1238.72": "Like hospital work, where the third leading cause of death",
    "1238.72-1240.72": "is physician error.",
    "1240.72-1245.72": "By augmenting drivers, physicians, nurses with AI systems,",
    "1245.72-1248.72": "we can drive these statistics to the point where",
    "1249.72-1253.72": "we can drive these statistics down and save people's lives.",
    "1257.72-1258.72": "I am comfortable.",
    "1258.72-1262.72": "What I'm sad about is how slowly the propagation is.",
    "1262.72-1266.72": "I wish that we had them everywhere so that they could save lives",
    "1266.72-1268.72": "and reduce the number of",
    "1272.72-1275.72": "That is overblown, that is science fiction,",
    "1275.72-1277.72": "because we're talking about tools,",
    "1279.72-1281.72": "but not beings who are going to take over.",
    "1288.72-1291.72": "I think it means the same thing it's always meant,",
    "1291.72-1294.72": "but it is in a different technological context.",
    "1294.72-1296.72": "But there's nothing new here, right?",
    "1296.72-1298.72": "We used to work in agriculture.",
    "1298.72-1301.72": "Now we're having a conversation.",
    "1301.72-1303.72": "We used to not have the internet. Now we do.",
    "1303.72-1309.72": "But we're still going to live and love and hate, unfortunately,",
    "1309.72-1314.72": "and go through our lives in a fundamentally human way."
  }
}